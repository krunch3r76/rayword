task: create word browser

look up word and related forms and pick a random sample

summarize model:
	MainModel->get_total_texts_and_unsearched_counts
	total number of texts in corpus:
	total number of texts searched: //count_total// - //count_unsearched//
	total number of texts remaining: //count_unsearched//

checks whether nltk is installed
prompts the user for the word
looks up word forms
displays all forms
reports count of instances of word as written
reports count of instances of word in other forms
selects a random wordindex
downloads the text
identifies the sentence in which the word occurs
prints the paragraph
prompts for speech
run thru espeak

./wordbrowser
./wordbrowser/browse.py

depends: ../main/model/maindbmodel.py :: MainModel

to implement on MainModel

build_word_to_word_id_dict(\\wordlist\\)
------------------------------------
	--> //word_to_word_id//
	for each \\word\\ in wordlist
		select word_id from Words
		//word_to_word_id//[//word//]=word_id
	<-- //word_to_word_id//

count_word_indices_records_for_word_id(\\word_id\\)
-----------------------------------------------
	select count(*) from WordIndices where word_id = //word_id// -> //count//
	return //count//
	
build_word_id_to_count_dict(\\word_to_word_id\\)
---------------------------------
	//word_id_list// = [ word_id for word_id in //word_to_word_id//.values() ]
	--> //word_id_to_indices_count//
	for each \\word_id\\ in //word_id_list//
		count_word_indices_records_for_word_id(\\word_id\\) -> //indices_count_for_word_id//
		//word_id_to_indices_count//[//word_id//] = //indices_count_for_word_id//
	return //word_id_to_count//

.count_instances_of_words(wordlist, primary_word)
===================================
	build_word_to_word_id_dict(wordlist)a-> //word_to_word_id//
	build_word_id_to_count_dict(word_to_word_id) --> //word_id_to_count//
	-> //primary_word_count// = //word_id_to_count//[//word_to_word_id//[\\primary_word\\]]
	[[ len(word_id_to_count) > 1 ]]
		-> //non_primary_word_count// = [ sum( [count for count in word_id_to_count.values()][1:] ) ]
	<- //primary_word_count//, //non_primary_word_count//

randomly_select_word_index_record_given_word_id(\\word_id\\, raise_exception=True)
-----------------------------------------------------
	\\word_id_selected\\ = None
	select * from WordIndices WHERE word_id = \\word_id\\ ORDER BY RANDOM()
	[ len(//records//) > 0]
	return dict(//records//[0])	

	[!records > 0]
	[raise_exception] raise Exception

	[! raise exception] return \\word_id_selected\\ #None

.random_word_index(wordlist, prefer_primary=True)
============================
	build_word_to_word_id_dict(wordlist) -> //word_to_word_id//
	build_word_id_to_count_dict(//word_to_word_id//) -> //word_id_to_count//
	//is_primary// = False
	[[prefer_primary]]
	//primary_word_id// = word_to_word_id(//wordlist//[0])
	//primary_word_count// = //word_id_to_count//[//primary_word_id//]
		[[primary_word_count > 0]]
		//word_id_to_search_for// = //primary_word_id//
		//primary// = True

	[[!primary_word_count > 0]]
	for \\word_id\\, \\count\\ in //word_id_to_count//.items():
		[ count > 0]
		//word_id_to_search_for// = \\word_id\\
		break
	
	randomly_select_word_index_given_word_id(//word_id_to_search_for//) -> //WordIndexRecord//
	return //WordIndexRecord//, //is_primary//




downloads the text
app.worker.util.resource_loader :: load_resource(url, max_retries=3)

_construct_url_from_path(path, path_prefix)
-----------------------------
	prepend path_prefix


text, _ = load_resource


nltk_data_path = worker_dir / "nltk_data"
nltk.data.path.append(str(nltk_data_path))

